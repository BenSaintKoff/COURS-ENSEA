{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <h1 style=\"width:100%;height:10%;text-align:center;position:relative;top:40%;\">LAB 1: Régression Ridge -- Regression Lasso</h1>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation en Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette mise en œuvre, nous utiliserons l’ensemble de données sur le logement de Boston qui se trouve dans Sklearn. Nous avons l’intention de voir :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comment effectuer une régression Ridge et Lasso en Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparer les résultats avec un modèle de régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Importation and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "boston = load_boston()\n",
    "boston_df=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "#target variable\n",
    "boston_df['Price']=boston.target\n",
    "#preview\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data dimension\n",
    "boston_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deescriptives\n",
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(boston_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are cases of multicolinearity, we will drop a few columns\n",
    "boston_df.drop(columns = [\"INDUS\", \"NOX\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "sns.pairplot(boston_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution normale et linéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables devraient être normalement distribuées et linéaires. Cependant, la relation entre LSTAT et Price est non linéaire. Par conséquent, nous faisons une transformation logarithmique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will log the LSTAT Column\n",
    "boston_df.LSTAT = np.log(boston_df.LSTAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélation entre les différentes variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot again\n",
    "#pairplot\n",
    "sns.pairplot(boston_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview\n",
    "features = boston_df.columns[0:11]\n",
    "target = boston_df.columns[-1]\n",
    "\n",
    "#X and y values\n",
    "X = boston_df[features].values\n",
    "y = boston_df[target].values\n",
    "\n",
    "#splot\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "\n",
    "print(\"The dimension of X_train is {}\".format(X_train.shape))\n",
    "print(\"The dimension of X_test is {}\".format(X_test.shape))\n",
    "#Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de régression linéaire et de Ridge\n",
    "\n",
    "Nous construirons un modèle de régression linéaire et de crête, puis nous comparerons les coefficients dans un graphique. Le score du train et des ensembles d’essai nous aidera également à évaluer le rendement du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "lr = LinearRegression()\n",
    "\n",
    "#Fit model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "#prediction = lr.predict(X_test)\n",
    "\n",
    "#actual\n",
    "actual = y_test\n",
    "\n",
    "train_score_lr = lr.score(X_train, y_train)\n",
    "test_score_lr = lr.score(X_test, y_test)\n",
    "\n",
    "print(\"The train score for lr model is {}\".format(train_score_lr))\n",
    "print(\"The test score for lr model is {}\".format(test_score_lr))\n",
    "\n",
    "\n",
    "#Ridge Regression Model\n",
    "ridgeReg = Ridge(alpha=10)\n",
    "\n",
    "ridgeReg.fit(X_train,y_train)\n",
    "\n",
    "#train and test scorefor ridge regression\n",
    "train_score_ridge = ridgeReg.score(X_train, y_train)\n",
    "test_score_ridge = ridgeReg.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nRidge Model............................................\\n\")\n",
    "print(\"The train score for ridge model is {}\".format(train_score_ridge))\n",
    "print(\"The test score for ridge model is {}\".format(test_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant une valeur alpha de 10, l’évaluation du modèle, d'apprentissage et du test indique une meilleure performance sur le modèle de Ridge que sur le modèle de régression linéaire.\n",
    "\n",
    "Nous pouvons également tracer les coefficients pour les modèles linéaires et de Ridge ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we lot the coefficients or weights from the linear regression model\n",
    "pd.Series(lr.coef_, features).sort_values(ascending = True).plot(kind = \"bar\")\n",
    "plt.title(\"Linear Regression Coefficients\")\n",
    "plt.show()\n",
    "\n",
    "#we lot the coefficients or weights from the ridge regression model\n",
    "pd.Series(ridgeReg.coef_, features).sort_values(ascending = True).plot(kind = \"bar\")\n",
    "plt.title(\"Ridge Regression Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(features,ridgeReg.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\\alpha = 10$',zorder=7) \n",
    "#plt.plot(rr100.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Ridge; $\\alpha = 100$') \n",
    "plt.plot(features,lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison plot of Ridge and Linear regression model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Lasso ( Least Absolute Shrinkage and Selection Operator )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "#print(\"The train score for lr model is {}\".format(train_score_lr))\n",
    "#print(\"The test score for lr model is {}\".format(test_score_lr))\n",
    "\n",
    "#Building a ri\n",
    "print(\"\\nLasso Model............................................\\n\")\n",
    "lasso = Lasso(alpha = 10)\n",
    "lasso.fit(X_train,y_train)\n",
    "train_score_ls =lasso.score(X_train,y_train)\n",
    "test_score_ls =lasso.score(X_test,y_test)\n",
    "\n",
    "print(\"The train score for ls model is {}\".format(train_score_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lasso.coef_, features).sort_values(ascending = True).plot(kind = \"bar\")\n",
    "plt.title(\"Lasso Regression Coefficients at alpha = 10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the linear CV model\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "#Lasso Cross validation\n",
    "lasso_cv = LassoCV(alphas = [0.0001, 0.001,0.01, 0.1, 1, 10], random_state=0).fit(X_train, y_train)\n",
    "\n",
    "#score\n",
    "print(\"The train score for lasso model is: {}\".format(lasso_cv.score(X_train, y_train)))\n",
    "print(\"The train score for lasso model is: {}\".format(lasso_cv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : Une approche semblable pourrait être utilisée pour le modèle de régression de Ridge, ce qui pourrait donner de meilleurs résultats. Dans le package sklearn, la fonction RidgeCV fonctionne de façon similaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the linear CV model\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "#Lasso Cross validation\n",
    "ridge_cv = RidgeCV(alphas = [0.0001, 0.001,0.01, 0.1, 1, 10]).fit(X_train, y_train)\n",
    "\n",
    "#score\n",
    "print(\"The train score for ridge model is {}\".format(ridge_cv.score(X_train, y_train)))\n",
    "print(\"The train score for ridge model is {}\".format(ridge_cv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle sera formé sur différentes valeurs alpha \n",
    "spécifiées dans la fonction LassoCV. Nous pouvons observer une meilleure performance du modèle, en supprimant l’effort fastidieux de changer manuellement les valeurs alpha.\n",
    "\n",
    "Nous pouvons comparer les coefficients du modèle lasso avec le reste des modèles (linéaire et Ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot size\n",
    "plt.figure(figsize = (10, 10))\n",
    "#add plot for ridge regression\n",
    "plt.plot(features,ridgeReg.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\\alpha = 10$',zorder=7) \n",
    "\n",
    "#addd plot for lasso regression\n",
    "plt.plot(lasso_cv.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'lasso; $\\alpha = grid$') \n",
    "\n",
    "#add plot for linear model\n",
    "plt.plot(features,lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')\n",
    "\n",
    "#rotate axis\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison plot of Ridge, Lasso and Linear regression model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Nous avons vu une mise en œuvre de modèles de régression de Ridge et de LASSO et des concepts théoriques et mathématiques qui sous-tendent ces techniques. \n",
    "\n",
    "    1/La fonction de coût pour la régression de crête et de lasso est similaire. Cependant, la régression de crête prend le carré des coefficients et lasso prend la magnitude.\n",
    "    2/La régression de Lasso peut être utilisée pour la sélection automatique de fonctionnalités, car la géométrie de sa région contrainte permet des valeurs de coefficient inertes à zéro.\n",
    "    3/Une valeur alpha de zéro dans le modèle de crête ou de lasso aura des résultats semblables au modèle de régression.\n",
    "    4/Plus la valeur alpha est grande, plus la pénalisation est agressive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
